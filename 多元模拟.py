import pandas as pd
import numpy as np
import itertools
import logging
import æ¨¡æ‹Ÿå‰é¢„å¤„ç†
import ä»·æ ¼å¤„ç†
import argparse
from datetime import datetime
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from concurrent.futures import ThreadPoolExecutor
from functools import partial
from concurrent.futures import ProcessPoolExecutor
import traceback
import ast
import time
######################################## å‡½æ•°è¿ç®— ########################################################################
# ç”¨æ¥è®¡ç®—ç£¨æŸ
def get_wear_values_by_skin_name(max_itemfloa, min_itemfloa,itemfloat_avedge,Weight_ls):
    # Step 1: æƒé‡ä¹˜ç§¯ï¼Œè¾“å‡º shape: (n,)
    offset_weights = (itemfloat_avedge @ Weight_ls.T).flatten()  # shape: (n,)
    # Step 2: å˜å½¢ä¸º (n, 1, 1) ä»¥ä¾¿å¹¿æ’­
    offset_weights = offset_weights[:, None, None]  # shape: (n, 1, 1)
    # Step 3: æ‰©å±• max/min ä¸º (1, m, k)
    delta = (max_itemfloa - min_itemfloa)[None, :, :]  # shape: (1, m, k)
    min_itemfloa = min_itemfloa[None, :, :]            # shape: (1, m, k)
    # Step 4: å¹¿æ’­åè¿ç®— -> shape: (n, m, k)
    wear_values = delta * offset_weights + min_itemfloa
    return wear_values  # shape: (n, m, kï¼‰



def get_thread_count(num_tasks):
    if num_tasks > 100000:
        return 20
    elif num_tasks > 10000:
        return 10
    elif num_tasks > 5000:
        return 5
    else:
        return 1
# è®¡ç®—ç£¨æŸçŸ©é˜µ
def convert_wear_to_price_fast(wear_matrix, skin_id, secret_df):
    wear_matrix = np.array(wear_matrix)
    n, m, k = wear_matrix.shape
    # å°† secret è¡¨è½¬ä¸ºæ˜ å°„å­—å…¸ {(skin_name_id, ç£¨æŸ): price}
    price_map = {
        (row['skin_name_id'], row['ç£¨æŸ']): row['price']
        for _, row in secret_df.iterrows()
    }
    # å°† skin_id åˆ—è¡¨è½¬ä¸ºäºŒç»´ numpy æ•°ç»„ï¼Œshape = (m, k)
    skin_id_matrix = np.zeros((m, k), dtype=int)
    for j in range(m):
        for l in range(len(skin_id[j])):
            skin_id_matrix[j, l] = skin_id[j][l]
    # é¢„åˆ†é…ç»“æœçŸ©é˜µ
    result = np.zeros_like(wear_matrix)
    # å‘é‡åŒ–éå†æ‰€æœ‰ä½ç½®
    for j in range(m):
        for l in range(k):
            skin = skin_id_matrix[j, l]
            if skin == 0:
                continue
            # å–å‡ºæ‰€æœ‰ n ä¸ªç»„åˆä¸‹ç¬¬ j, l ä½ç½®çš„ç£¨æŸå€¼
            wear_column = wear_matrix[:, j, l]
            # è½¬æ¢ä¸ºç£¨æŸç­‰çº§åˆ—è¡¨
            wear_labels = np.vectorize(get_wear_label)(wear_column)
            # ä»æ˜ å°„ä¸­æŸ¥æ‰¾ä»·æ ¼
            prices = np.array([
                price_map.get((skin, label), 0)
                for label in wear_labels
            ])
            # å¡«å…¥ç»“æœ
            result[:, j, l] = prices
    return result



#æœŸæœ›çŸ©é˜µè®¡ç®—
def calc_expected_profit(price_matrix, Weight_ls):
    n, m, k = price_matrix.shape

    # Step 1: å¹³å‡æ¯è¡Œçš„ä»·æ ¼ -> shape: (n, m)
    avg_price_per_row = price_matrix.mean(axis=2)

    # Step 2: æ¯è¡Œä¹˜ä»¥å¯¹åº”çš„æƒé‡ -> shape: (n, m)
    weighted_price = avg_price_per_row * Weight_ls

    # Step 3: æŒ‰è¡Œæ±‚å’Œ -> shape: (n, 1)
    expected_profit = np.sum(weighted_price, axis=1, keepdims=True)

    return expected_profit
# è®¡ç®—æ€»æˆæœ¬çŸ©é˜µ
def calc_total_cost(price_per_unit, number_ls):
    price_per_unit = np.array(price_per_unit).reshape(1, -1)  # shape (1, 3)
    total_cost = np.sum(number_ls * price_per_unit, axis=1, keepdims=True)  # shape (n, 1)
    return total_cost
# è®¡ç®—æ”¶ç›Šç‡çŸ©é˜µ
def calc_yield_rate(expected_profit, total_cost):
    # é¿å…é™¤ä»¥ 0
    with np.errstate(divide='ignore', invalid='ignore'):
        yield_rate = np.true_divide(expected_profit, total_cost)
        yield_rate[~np.isfinite(yield_rate)] = 0  # å°† inf å’Œ nan è½¬ä¸º 0
    return yield_rate

# è®¡ç®—ç»„åˆç´¢å¼•
def find_combo_index(idx, index_ranges):
    for i, (start, end) in enumerate(index_ranges):
        if start <= idx < end:
            if i==0:
                return 0
            return i//len(all_combinations_num)
    raise IndexError(f"Index {idx} ä¸åœ¨ä»»ä½•ç»„åˆèŒƒå›´å†…ï¼")

def get_wear_label(itemfloat_num):
    if itemfloat_num < 0.07:
        return "å´­æ–°å‡ºå‚"
    elif itemfloat_num < 0.15:
        return "ç•¥æœ‰ç£¨æŸ"
    elif itemfloat_num < 0.38:
        return "ä¹…ç»æ²™åœº"
    elif itemfloat_num < 0.45:
        return "ç ´æŸä¸å ª"
    else:
        return "æˆ˜ç—•ç´¯ç´¯"

def chunk_list(lst, size):
    for i in range(0, len(lst), size):
        yield lst[i:i + size]

def process_single_index(
    idx,
    combo_sample_index_ranges,
    all_combination,
    skin_id_map_list,
    new_skin_itemfloat,
    converted_matrix,
    expected_profit,
    total_cost,
    yield_rate,
    number_ls,
    Weight_ls,
    skin_id_lz,
    n,
    box_names,
    skin_name_map,
    lz_skin_name_map,
    itemfloat_avedge_dict,
    quality_dict
):
    try:
        j = -1
        for i, (start, end) in enumerate(combo_sample_index_ranges):
            if start <= idx < end:
                j = i
                break
        if j == -1 or j >= len(skin_id_map_list):
            return []

        rows = []
        box_skin_sets = [set(skin_id_map_list[j][i]) for i in range(n)]

        for j2 in range(len(skin_id_map_list[j])):
            for k in range(len(skin_id_map_list[j][j2])):
                sid = skin_id_map_list[j][j2][k]
                if sid == 0:
                    continue
                wear = new_skin_itemfloat[idx, j2, k]
                price = converted_matrix[idx, j2, k]
                label = get_wear_label(wear)
                row = []
                original_comb = all_combination[j]
                converted_comb = [box_names.get(box_id, f"ID_{box_id}") for box_id in original_comb]
                row.extend(converted_comb)
                row.append(skin_name_map.get(sid, f"ID_{sid}"))
                row.append(round(price, 2))
                row.append(round(expected_profit[idx], 2))
                row.append(round(total_cost[idx], 2))
                row.append(round(yield_rate[idx], 4))
                found = False
                for box_index in range(n):
                    if sid in box_skin_sets[box_index]:
                        box_weight = Weight_ls[idx][box_index]
                        box_skin_count = len(box_skin_sets[box_index])
                        skin_prob = box_weight / box_skin_count if box_skin_count else 0
                        found = True
                        break
                if not found:
                    skin_prob = 0
                row.append(round(skin_prob, 6))
                row.extend(list(number_ls[idx]))
                row.extend([label, round(wear, 6)])
                for i in range(n):
                    lz_id = skin_id_lz[j][i]
                    lz_name = lz_skin_name_map.get(lz_id, f"ID_{lz_id}")
                    lz_wear = itemfloat_avedge_dict.get(lz_id, 0)
                    lz_price = quality_dict.get(lz_id, 0)
                    row.extend([lz_name, round(lz_wear, 6), round(lz_price, 2)])
                rows.append(row)
        return rows
    except Exception as e:
        logging.error(f"âŒ æ„é€  index {idx} å‡ºé”™: {e}\n{traceback.format_exc()}")
        return []

def process_batch_indices(idx_batch, **kwargs):
    all_rows = []
    for idx in idx_batch:
        rows = process_single_index(idx, **kwargs)
        all_rows.extend(rows)
    return all_rows

def save_results_to_excel(
    all_combination,
    skin_id_map_list,
    number_ls,
    Weight_ls,
    new_skin_itemfloat,
    converted_matrix,
    expected_profit,
    total_cost,
    yield_rate,
    secret_df,
    Superior,
    Confidentiality,
    skin_id_lz,
    threshold: float,
    itemfloat_avedge_dict,
    quality_dict,
    box_names,
    save_folder: str,
    save_name: str,
    n: int,
    plot_distribution=True
):
    os.makedirs(save_folder, exist_ok=True)
    save_path = os.path.join(save_folder, save_name.replace('.xlsx', '.csv'))

    combo_sample_index_ranges = []
    start = 0
    for arr in number_ls:
        count = arr.shape[0]
        combo_sample_index_ranges.append((start, start + count))
        start += count

    max_index = start
    filtered_idx = np.where((yield_rate > threshold) & (np.arange(len(yield_rate)) < max_index))[0]

    skin_name_map = Superior.set_index('skin_name_id')['skin_name'].to_dict()
    lz_skin_name_map = Confidentiality.set_index('skin_name_id')['skin_name'].to_dict()

    all_columns = (
        [f"ç»„åˆç®±å­{i+1}" for i in range(n)] +
        ["äº§ç‰©çš®è‚¤åç§°", "äº§ç‰©å”®ä»·", "æœŸæœ›æ”¶ç›Š", "ç»„åˆæˆæœ¬", "ç»„åˆæ”¶ç›Šç‡"] +
        ["çš®è‚¤æ¦‚ç‡"] +
        [f"ç»„åˆ{i+1}_æ•°é‡" for i in range(n)] +
        ["ç£¨æŸåŒºé—´", "ç£¨æŸå€¼"] +
        [
            label
            for i in range(n)
            for label in [
                f"ç‚‰æ¸£{i + 1}_çš®è‚¤åç§°",
                f"ç‚‰æ¸£{i + 1}_å¹³å‡ç£¨æŸ",
                f"ç‚‰æ¸£{i + 1}_å‡ä»·"]
        ]
    )

    batch_size = 10000
    mini_batch_size = 500  # æé«˜æ¯ä¸ªè¿›ç¨‹å¤„ç†é‡
    write_every = 5
    buffer_rows = []

    batches = list(chunk_list(filtered_idx, batch_size))
    for bi, batch in enumerate(tqdm(batches, desc="ğŸš€ åˆ†æ‰¹æ„é€ ç»“æœè¡Œ")):

        print(f"ğŸ§µ ç¬¬ {bi+1}/{len(batches)} æ‰¹æ¬¡ï¼šä½¿ç”¨å¤šè¿›ç¨‹å¤„ç† {len(batch)} æ¡æ•°æ®")
        mini_batches = list(chunk_list(batch, mini_batch_size))

        kwargs = dict(
            combo_sample_index_ranges=combo_sample_index_ranges,
            all_combination=all_combination,
            skin_id_map_list=skin_id_map_list,
            new_skin_itemfloat=new_skin_itemfloat,
            converted_matrix=converted_matrix,
            expected_profit=expected_profit,
            total_cost=total_cost,
            yield_rate=yield_rate,
            number_ls=number_ls,
            Weight_ls=Weight_ls,
            skin_id_lz=skin_id_lz,
            n=n,
            box_names=box_names,
            skin_name_map=skin_name_map,
            lz_skin_name_map=lz_skin_name_map,
            itemfloat_avedge_dict=itemfloat_avedge_dict,
            quality_dict=quality_dict
        )

        func = partial(process_batch_indices, **kwargs)

        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
            all_results = list(tqdm(executor.map(func, mini_batches), total=len(mini_batches), desc="å­ä»»åŠ¡å¤„ç†ä¸­"))

        flat_rows = [row for sublist in all_results for row in sublist]
        buffer_rows.extend(flat_rows)

        # æ¯ N æ‰¹å†™å…¥ä¸€æ¬¡
        if (bi + 1) % write_every == 0 or (bi + 1) == len(batches):
            if buffer_rows:
                df = pd.DataFrame(buffer_rows, columns=all_columns)
                df.to_csv(save_path, index=False, mode='a', encoding='utf-8-sig', header=not os.path.exists(save_path))
                print(f"ğŸ“„ å†™å…¥ {len(buffer_rows)} è¡Œæ•°æ®")
                buffer_rows.clear()

    print(f"âœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜ä¸º CSV è‡³ï¼š{save_path}")
    if plot_distribution:
        from matplotlib import pyplot as plt
        import seaborn as sns
        plt.figure(figsize=(10, 6))
        sns.histplot(yield_rate, kde=True, bins=30, color='skyblue')
        plt.axvline(threshold, color='red', linestyle='--', label=f'threshold: {threshold}')
        plt.title("Yield Distribution Chart")
        plt.xlabel("Yield")
        plt.ylabel("Frequency")
        plt.legend()
        plt.tight_layout()
        img_path = os.path.join(save_folder, f"æ”¶ç›Šç‡åˆ†å¸ƒå›¾{today}_{input_ls[0]}_{n}.png")
        plt.savefig(img_path)
        plt.close()
        print(f"ğŸ“ˆ æ”¶ç›Šç‡åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°ï¼š{img_path}")

def pad_to_shape(tensor_list, target_k):
    """
    å¯¹ tensor_list ä¸­æ¯ä¸ªå½¢çŠ¶ä¸º (n, m, k_i) çš„å¼ é‡ï¼Œåœ¨ axis=2 ä¸Š pad åˆ° target_kã€‚
    """
    padded = []
    for t in tensor_list:
        n, m, k = t.shape
        if k == target_k:
            padded.append(t)
        else:
            # æ„å»º shape = (n, m, target_k - k) çš„ 0 çŸ©é˜µ
            pad_shape = (n, m, target_k - k)
            zeros = np.zeros(pad_shape)
            padded_tensor = np.concatenate([t, zeros], axis=2)
            padded.append(padded_tensor)
    return padded


def generate_partitions(n, k):
    """
    ç”Ÿæˆæ‰€æœ‰é•¿åº¦ä¸º n çš„éè´Ÿæ•´æ•°åˆ†åŒºï¼Œä½¿å¾—ï¼š
    - æ‰€æœ‰å€¼ â‰¥1ï¼ˆå³æ¯ä¸ªç›’å­è‡³å°‘è¢«å¼€ä¸€æ¬¡ï¼‰
    - æ‰€æœ‰å€¼ä¹‹å’Œä¸º kï¼ˆé»˜è®¤ 10ï¼‰
    - è¿”å›çš„åˆ†åŒºå·²æ’åºå»é‡
    """
    results = []

    def backtrack(path, remaining):
        if len(path) == n:
            if remaining == 0:
                results.append(tuple(sorted(path)))
            return
        # è‡³å°‘ç•™å‡º (n - len(path) - 1) ä¸ª 1 ç»™åé¢çš„
        for i in range(1, remaining - (n - len(path) - 1) + 1):
            backtrack(path + [i], remaining - i)

    if k >= n:
        backtrack([], k)
    return sorted(set(results))




##################################### ä¸»å¾ªç¯ï¼šå¤šçº¿ç¨‹ç‰ˆæœ¬ ##########################################################################



def process_single_combination(i, n, Superior, secret, Confidentiality,
                               lookup_itemfloat_avedge, lookup_quality, all_combinations_num):
    try:
        i_ls = list(i)
        skin_id = [
            Superior[Superior['weapon_box_id'] == box]['skin_name_id'].tolist()
            for box in i_ls
        ]

        lookup_dict_nim = Superior.set_index('skin_name_id')['min_itemfloa'].to_dict()
        lookup_dict_max = Superior.set_index('skin_name_id')['max_itemfloa'].to_dict()
        new_skin_min = [[lookup_dict_nim.get(sid, 0) for sid in group] for group in skin_id]
        new_skin_max = [[lookup_dict_max.get(sid, 0) for sid in group] for group in skin_id]

        if any(len(sublist) == 0 for sublist in new_skin_min):
            return None

        max_len = max(len(sublist) for sublist in new_skin_min)
        new_skin_min = np.array([sublist + [0] * (max_len - len(sublist)) for sublist in new_skin_min])
        new_skin_max = np.array([sublist + [0] * (max_len - len(sublist)) for sublist in new_skin_max])

        skin_id_lz = [
            Confidentiality[Confidentiality['weapon_box_id'] == box]['skin_name_id'].tolist()[0]
            for box in i_ls
        ]
        itemfloat_avedge = np.array([lookup_itemfloat_avedge.get(sid, 0) for sid in skin_id_lz])
        quality_lz_ls = [lookup_quality.get(sid, 0) for sid in skin_id_lz]

        number_ls = np.array(generate_partitions(n, 10))
        Weight_ls = number_ls / 10
        new_skin_itemfloat = get_wear_values_by_skin_name(new_skin_max, new_skin_min, itemfloat_avedge, Weight_ls)
        converted_matrix = convert_wear_to_price_fast(new_skin_itemfloat, skin_id, secret)
        expected_profit = calc_expected_profit(converted_matrix, Weight_ls)
        total_cost = calc_total_cost(quality_lz_ls, number_ls)
        yield_rate = calc_yield_rate(expected_profit, total_cost)

        return {
            "comb": i_ls,
            "skin_id": skin_id,
            "skin_id_lz": skin_id_lz,
            "number_ls": number_ls,
            "Weight_ls": Weight_ls,
            "itemfloat": new_skin_itemfloat,
            "converted": converted_matrix,
            "profit": expected_profit,
            "cost": total_cost,
            "yield": yield_rate
        }

    except Exception as e:
        logging.error(f"âŒ å¤„ç†ç»„åˆ {i} å‡ºé”™ï¼š{e}")
        return None


if __name__ == "__main__":

    # é…ç½®æ—¥å¿—è®°å½•å™¨
    logging.basicConfig(filename='error_log.txt', level=logging.ERROR,
                        format='%(asctime)s - %(levelname)s - %(message)s')
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", type=str, required=True)
    parser.add_argument("--input1", type=str, required=True)
    parser.add_argument("--input_ls", type=str, required=True)
    parser.add_argument("--output", type=str, required=True)
    parser.add_argument('--n', type=int, default=3, help='ç®±å­æ•°é‡')
    parser.add_argument('--threshold', type=float, default=0.8, help='ä¿å­˜é˜ˆå€¼')
    # ç®±å­æ•°é‡
    n = int(parser.parse_args().n)

    # ä¿å­˜é˜ˆå€¼
    threshold = float(parser.parse_args().threshold)

    # è¯»å–æ–‡ä»¶
    box_fill = parser.parse_args().input
    file_old = parser.parse_args().input1
    input_ls = ast.literal_eval(parser.parse_args().input_ls)
    folder = parser.parse_args().output
    if input_ls[4] == 0:
        itemfloat_fill_path = "data/é¥°å“ç£¨æŸåŒºé—´.xlsx"
    if input_ls[4] == 1:
        itemfloat_fill_path = "data/é¥°å“ç£¨æŸåŒºé—´StatTrak.xlsx"

    skin_file = "data/csé¥°å“ç¼–å·/å¯¹åº”ç¼–å·.xlsx"
    # å­˜å‚¨è·¯å¾„
    today = datetime.now().strftime("%Y-%m-%d")
    if input_ls[4]==1:
        StatTrak_if = "StatTrakâ„¢"
    else:
        StatTrak_if = "æ™®é€š"
    #å†folderè·¯å¾„ä¸‹åˆ›å»ºä¸€åä¸º todayçš„æ–‡ä»¶å¤¹
    folder = os.path.join(folder, f"{today}_{StatTrak_if}")
    os.makedirs(folder, exist_ok=True)
    save_path = os.path.join(folder, f"analysis_results_{today}_{input_ls[0]}_{input_ls[4]}.xlsx")
############################### æ•°æ®é¢„å¤„ç† ###############################################################################
    # å¯¼å…¥ç£¨æŸæ•°æ®
    itemfloat_fill = pd.read_excel(itemfloat_fill_path)
    # ä»·æ ¼å¤„ç†ä¼šå°†box_fill, skin_fileä¸­æœ‰ç”¨çš„æ•°æ®åˆ—æå–å‡ºæ¥
    box_fill = ä»·æ ¼å¤„ç†.main(box_fill, skin_file)

    # é¢„å¤„ç†å°†æ•°æ®åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ† Superioræ˜¯é«˜å“è´¨çš®è‚¤ä¸åŒ…å«å¤šä¸ªç£¨æŸåŒºé—´ï¼Œsecretæ˜¯é«˜å“è´¨çš®è‚¤åŒ…å«å¤šä¸ªç£¨æŸï¼ŒConfidentialityæ˜¯åªä¿ç•™æ¯ä¸ªæ­¦å™¨ç®±ä»·æ ¼æœ€ä½çš„ä½å“è´¨çš®è‚¤
    (Superior, secret, Confidentiality) = æ¨¡æ‹Ÿå‰é¢„å¤„ç†.clean_box(box_fill, itemfloat_fill,file_old,input_ls)
    # ä»Confidentialityä¸­è·å–æ‰€æœ‰çš„ç®±å­åç§°
    box_names = Confidentiality['weapon_box_id'].unique()
    # è·å–æ‰€æœ‰ç®±å­çš„ç»„åˆå¹¶è½¬åŒ–ä¸ºåˆ—è¡¨
    all_combination = list(itertools.combinations(box_names, n))
##################################### ä¸»å¾ªç¯ ##########################################################################
    all_data_rows = []
    all_combinations_num = generate_partitions(n, 10)
    lookup_itemfloat_avedge = Confidentiality.set_index('skin_name_id')['itemfloat'].to_dict()
    lookup_quality = Confidentiality.set_index('skin_name_id')['price'].to_dict()
    lookup_box = Confidentiality.set_index('weapon_box_id')['weapon_box'].to_dict()

    # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
    your_skin_id_list = []
    all_combination_used = []
    all_skin_id_lz = []
    all_number_ls = []
    all_Weight_ls = []
    all_itemfloat_matrix = []
    all_converted_matrix = []
    all_expected_profit = []
    all_total_cost = []
    all_yield_rate = []

    # å¤šçº¿ç¨‹æ‰§è¡Œ
    thread_count = get_thread_count(len(all_combination))
    print(f"ğŸ§µ æ­£åœ¨ä½¿ç”¨ {thread_count} ä¸ªè¿›ç¨‹å¤„ç† {len(all_combination)} ä¸ªç»„åˆ...")

    func = partial(
        process_single_combination,
        n=n,
        Superior=Superior,
        secret=secret,
        Confidentiality=Confidentiality,
        lookup_itemfloat_avedge=lookup_itemfloat_avedge,
        lookup_quality=lookup_quality,
        all_combinations_num=all_combinations_num
    )

    with ProcessPoolExecutor(max_workers=thread_count) as executor:
        results = list(tqdm(
            executor.map(func, all_combination),
            total=len(all_combination),
            desc="å¤šè¿›ç¨‹å¤„ç†ä¸­..."
        ))

    for result in results:
        if result is None:
            continue
        all_combination_used.append(result["comb"])
        your_skin_id_list.append(result["skin_id"])
        all_skin_id_lz.append(result["skin_id_lz"])
        all_number_ls.append(result["number_ls"])
        all_Weight_ls.append(result["Weight_ls"])
        all_itemfloat_matrix.append(result["itemfloat"])
        all_converted_matrix.append(result["converted"])
        all_expected_profit.append(result["profit"])
        all_total_cost.append(result["cost"])
        all_yield_rate.append(result["yield"])

    # è¡¥é½ shape çš„ç»´åº¦
    max_k = max(arr.shape[2] for arr in all_converted_matrix)
    converted_matrix = np.concatenate(pad_to_shape(all_converted_matrix, max_k), axis=0)
    new_skin_itemfloat = np.concatenate(pad_to_shape(all_itemfloat_matrix, max_k), axis=0)

    # æ‹¼æ¥å‘é‡å€¼
    yield_rate = np.vstack(all_yield_rate).flatten()
    expected_profit = np.vstack(all_expected_profit).flatten()
    total_cost = np.vstack(all_total_cost).flatten()
    number_ls = np.vstack(all_number_ls)
    Weight_ls = np.vstack(all_Weight_ls)

    save_results_to_excel(
        all_combination=all_combination_used,  # æ¯ç»„ç»„åˆç¼–å·ï¼ˆ84ä¸ªï¼‰
        skin_id_map_list=your_skin_id_list,  # æ¯ç»„ç»„åˆå¯¹åº”çš„ skin_idï¼ˆ84ä¸ªåˆ—è¡¨ï¼‰
        number_ls=number_ls,  # (N_total, n)
        Weight_ls=Weight_ls,  # (N_total, n)
        new_skin_itemfloat=new_skin_itemfloat,  # (N_total, m, k)
        converted_matrix=converted_matrix,  # (N_total, m, k)
        expected_profit=expected_profit,  # (N_total,)
        total_cost=total_cost,  # (N_total,)
        yield_rate=yield_rate,  # (N_total,)
        secret_df=secret,  # secret è¡¨
        Superior=Superior,  # æ¥æºçš®è‚¤è¡¨
        Confidentiality=Confidentiality,  # ç‚‰æ¸£çš®è‚¤è¡¨
        skin_id_lz=all_skin_id_lz,  # ç‚‰æ¸£ ID åˆ—è¡¨ï¼ˆ84ç»„ï¼‰
        threshold=threshold,  # ä½ çš„é˜ˆå€¼ float
        itemfloat_avedge_dict=lookup_itemfloat_avedge,  # ç‚‰æ¸£ id â†’ ç£¨æŸ dict
        quality_dict=lookup_quality,  # ç‚‰æ¸£ id â†’ price dict
        box_names = lookup_box,
        save_folder=folder,  # ä¿å­˜ç›®å½•
        save_name=f"analysis_results_{today}_{input_ls[0]}_{n}.xlsx",  # ä¿å­˜æ–‡ä»¶å
        n=n,  # ç®±å­æ•°é‡
        plot_distribution=True  # æ˜¯å¦ç”»æ”¶ç›Šç‡åˆ†å¸ƒå›¾
    )



